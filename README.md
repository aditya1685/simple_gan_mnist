# GAN for MNIST Digit Generation

This repository contains a PyTorch implementation of a Generative Adversarial Network (GAN) for generating MNIST digit images. The model includes a Generator and a Discriminator, both implemented as neural networks, and uses the MNIST dataset to train the GAN to generate realistic digit images.

## Overview

A GAN consists of two neural networks:
1. **Generator (G):** Learns to generate fake images from random noise.
2. **Discriminator (D):** Learns to distinguish real images from fake images.

These two models are trained simultaneously in a game-theoretic framework, where the Generator tries to fool the Discriminator, and the Discriminator tries to correctly classify real and fake images.

## Model Architecture

### Generator
- Input: Random noise vector of size `z_dim` (64).
- Two fully connected layers with LeakyReLU activation.
- Output: Image vector of size `img_dim` (784 for 28x28 grayscale images).
- Final activation: Tanh.

### Discriminator
- Input: Flattened image vector of size `img_dim`.
- Two fully connected layers with LeakyReLU activation.
- Output: Scalar probability.
- Final activation: Sigmoid.

## Prerequisites

### Libraries Required:
- PyTorch
- torchvision
- TensorBoard

### Installation:
1. Install dependencies:
   ```bash
   pip install torch torchvision tensorboard
   ```

## Training the GAN

### Hyperparameters:
- Learning Rate: 3e-4
- Latent Dimension (`z_dim`): 64
- Image Dimension (`img_dim`): 784 (28x28)
- Batch Size: 32
- Number of Epochs: 200

### Training Steps:
1. **Discriminator Training:**
   - Calculate the loss for real images.
   - Calculate the loss for fake images generated by the Generator.
   - Update the Discriminator to minimize the combined loss.

2. **Generator Training:**
   - Generate fake images from random noise.
   - Calculate the loss based on the Discriminator's output for these images.
   - Update the Generator to maximize the Discriminator's probability of classifying fake images as real.

3. Log images and metrics to TensorBoard for visualization.

### Running the Training Script:
Run the script using:
```bash
python simple_mnist_gan.py
```

### Output:
- Training progress will be logged to the console.
- Generated and real images will be saved and visualized using TensorBoard:
  ```bash
  tensorboard --logdir=logs
  ```

## Key Sections in the Code

### Data Preparation
- Loads the MNIST dataset using `torchvision.datasets.MNIST`.
- Applies transformations including normalization.

### Model Definition
- `Discriminator`: Defined as `nn.Module`.
- `Generator`: Defined as `nn.Module`.

### Loss Functions
- Binary Cross Entropy Loss (`BCELoss`) is used for both the Generator and Discriminator.

### Optimization
- Adam optimizer with a learning rate of `3e-4`.

### Logging and Visualization
- TensorBoard is used to log real and fake images during training.
- Visualize training progress by running TensorBoard.

## Results
- The GAN generates MNIST-like digit images after training.
- Real and generated images can be compared in TensorBoard logs.

## Notes
- Adjust the hyperparameters to experiment with different configurations.
- Ensure a GPU is available for faster training (`device = "cuda" if torch.cuda.is_available() else "cpu"`).

## Acknowledgments
- This implementation is based on PyTorch and TensorBoard documentation.
- MNIST dataset is provided by `torchvision.datasets`.

